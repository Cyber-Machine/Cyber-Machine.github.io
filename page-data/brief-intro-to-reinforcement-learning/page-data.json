{"componentChunkName":"component---node-modules-lekoarts-gatsby-theme-minimal-blog-core-src-templates-post-query-tsx","path":"/brief-intro-to-reinforcement-learning","result":{"data":{"post":{"slug":"/brief-intro-to-reinforcement-learning","title":"Brief intro to Reinforcement Learning.","date":"08.10.2022","tags":[{"name":"Deep Learning","slug":"deep-learning"},{"name":"Reinforcement Learning","slug":"reinforcement-learning"},{"name":"Mathematics","slug":"mathematics"}],"description":null,"canonicalUrl":null,"body":"var _excluded = [\"components\"];\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nvar _frontmatter = {\n  \"title\": \"Brief intro to Reinforcement Learning.\",\n  \"date\": \"2022-10-08T00:00:00.000Z\",\n  \"tags\": [\"Deep Learning\", \"Reinforcement Learning\", \"Mathematics\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"Artificial Intelligence has been evolving quite a lot in recent years, and there are a lot of breakthroughs that are happening since the inception of Deep learning, surplus of data and \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.researchgate.net/publication/325023664_Performance_of_CPUsGPUs_for_Deep_Learning_workloads\"\n  }, \"enhanced hardware (GPU's / TPU's)\"), \" & \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://jax.readthedocs.io/en/latest/notebooks/quickstart.html\"\n  }, \"acclerated programming\"), \".\"), mdx(\"p\", null, \"Currently AI has achieved a significant amount of things such as \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.deepmind.com/research/highlighted-research/alphago\"\n  }, \"beating human in games\"), \", \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://cdn.openai.com/papers/whisper.pdf\"\n  }, \"human-level speech recognition\"), \" towards \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://ai.googleblog.com/2022/07/mlgo-machine-learning-framework-for.html\"\n  }, \"optimizing compilers\"), \", and \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.nature.com/articles/s41586-022-05172-4\"\n  }, \"developing algorithms\"), \".\"), mdx(\"p\", null, \"Reinforcement Learning is one of the driving force that led to this innovations the past few years.\"), mdx(\"h2\", null, \"Reinforcement Learning\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"Reinforcement learning problems involve learning what to do\\u2014how to map situations to actions\\u2014so as to maximize a numerical reward signal. In\\nan essential way they are closed-loop problems because the learning system\\u2019s actions influence its later inputs. \"), mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf\"\n  }, \"Richard S. Sutton and Andrew G. Barto\"))), mdx(\"p\", null, \"When I think of Reinforcement learning, I think about a space video game where we have the controls for our space guns and we have to shoot asteriods in space with limited ammunation.\\nIf we try to destroy all asteroids in space our ammo will run out and we won't be able to shoot nearby asteriod and that will lead to untimely demise of our ship and same thing would happen if we save too much ammo by not shooting asteriod.\\nSince it is a simple game we can try multiple turns and learn an optimal way of saving ourselves from the asteroids.\"), mdx(\"p\", null, \"We can apply A.I. (Reinforcement learning) to save ourselves from these attacks by training our model to learn the enough trail and error.\\nIn Reinforcement Learning we have:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"Agent\"), \" - Our Spaceship\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"Environment\"), \" - Space\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"State\"), \" - A part of environment seen by our spaceship\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"Action\"), \" - To shoot or not \"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"Reward\"), \" - Weather we are alive or not\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"Policy\"), \" - The continuous series of action till we end the game\")), mdx(\"p\", null, \"Together these forms the basis for Reinforcement Learning.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Reinforcement learning tries to learn a optimal policy through trail-and-error by maximizing rewards through actions in a particular environment.\")), mdx(\"p\", null, \"In order to build an optimal policy, the agent faces the dilemma of exploring new states while maximizing its overall reward at the same time. This is called \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://sites.cs.ucsb.edu/~suri/ccs130a/MultiArmBandit.pdf\"\n  }, \"Exploration vs Exploitation trade-off\"), \". To balance both, the best overall strategy may involve short term sacrifices. Therefore, the agent should collect enough information to make the best overall decision in the future.\"), mdx(\"p\", null, \"What I personally like about Reinforcement Learning is how it ties up mathematics and human nature.\"), mdx(\"p\", null, \"We humans learn a lot through experimentation and challenges, and we use those experiences to better suit us to our environment.\\nWe are constantly evolving and exploring our environment to overcome adversaries.\"), mdx(\"p\", null, \"While I was learning how to solve these problems I came up with a lot of things in field of probabilities and decision making such as Markov chain, Dynamic Programming, Monte-Carlo techniques and so on. I was intrigued by the fact that how these functions help our model to form better decision over time. \"), mdx(\"h2\", null, \"Techniques Used in Reinforcment Learning\"), mdx(\"h3\", null, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"\"\n  }, \"Markov Chains\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"A Markov chain is a mathemathical framework based on a probabilistic model of the environment. \")), mdx(\"h3\", null, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"https://en.wikipedia.org/wiki/Q-learning\"\n  }, \"Q-learning\")), mdx(\"h2\", null, \"Recent Advancements\"), mdx(\"h3\", null, \"Deep Learning\"), mdx(\"h3\", null, \"Acclerated Programming\"), mdx(\"h3\", null, \"More Powerful computer\"), mdx(\"h2\", null, \"Deep-Q-Learning\"), mdx(\"h3\", null), mdx(\"p\", null, \"Further Reading :\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://incompleteideas.net/book/ebook/node12.html\"\n  }, \"History of Reinforcement Learning\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://lilianweng.github.io/posts/2018-02-19-rl-overview/#sarsa-on-policy-td-control\"\n  }, \"lilianweng\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://computerhistory.org/blog/ai-and-play-part-2-go-and-deep-learning/\"\n  }, \"Computer History Museum\"))));\n}\n;\nMDXContent.isMDXComponent = true;","excerpt":"Artificial Intelligence has been evolving quite a lot in recent years, and there are a lot of breakthroughs that are happening since theâ€¦","timeToRead":2,"banner":null}},"pageContext":{"slug":"/brief-intro-to-reinforcement-learning","formatString":"DD.MM.YYYY"}},"staticQueryHashes":["2744905544","3090400250","318001574"]}